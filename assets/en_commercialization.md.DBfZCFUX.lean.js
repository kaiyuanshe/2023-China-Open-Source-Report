import{_ as s,D as r,c as l,I as n,w as i,U as a,m as e,a as t,o as d}from"./chunks/framework.SrqJXW5h.js";const Jt=JSON.parse('{"title":"OSS Commercialization","description":"","frontmatter":{"outline":"deep"},"headers":[],"relativePath":"en/commercialization.md","filePath":"en/commercialization.md","lastUpdated":1712657240000}'),c={name:"en/commercialization.md"},u=a("",20),h=e("br",null,null,-1),p=e("p",null,"Along with the growing AI popularity, the global AI market size is also growing rapidly. According to Deloitte, it will grow at a CAGR of 23% during 2017-2022, and is expected to reach seven trillion dollars in 2025.",-1),m=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"75%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-2.png",alt:"image002"})])])])])],-1),g=e("h4",{id:"_2-1-2-open-source-power-for-ai",tabindex:"-1"},[t("2.1.2 Open Source Power for AI "),e("a",{class:"header-anchor",href:"#_2-1-2-open-source-power-for-ai","aria-label":'Permalink to "2.1.2 Open Source Power for AI"'},"​")],-1),f=e("p",null,"The power of the open-source ecosystem has played an essential role in making such great strides in pre-trained models. This includes not only research from academia but also support from industry. Under the joint efforts of the open-source ecosystem, the performance of the open-source-based LLM is rapidly developing and gradually rivaling that of closed-source.",-1),y=e("p",null,[e("strong",null,"The power of open source from academia has contributed significantly to the evolution of AI technology")],-1),b=e("p",null,'Since Princeton University published ImageNET in 2009, a significant paper in computer vision, there has been a gradual increase in the number of papers related to AI machine learning. Over the years, researchers have proposed many open-source algorithms. By 2017, the number of papers on AI machine learning on Arxiv had reached over 25,000. The "Attention Is All You Need" paper was published that same year, introducing the open-source Transformer model. The publication of this paper led to a concentrated surge in research and papers on LLM. As a result, from 2017 to 2023, the number of Arxiv papers related to LLM surged to over 100,000. This surge also considerably accelerated the open-source development of related models and laid the theoretical foundation for the subsequent explosion of LLM technology.',-1),v=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"100%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-3.png",alt:"image003"})])])])])],-1),w=e("br",null,null,-1),_=e("div",{class:"info custom-block"},[e("p",{class:"custom-block-title"},"Expert Review"),e("p",null,[e("strong",null,"Willem Ning JIANG"),t("：This insight is quite exciting, and academic open-source plays a very important role.")])],-1),k=e("p",null,[e("strong",null,"The industry's open source power fuels rapid development of LLM")],-1),L=e("p",null,`With the ChatGPT LLM popularity, more and more technicians are devoted to the research and development of LLMs. In addition to closed-source products, many great open-source LLMs are also leading the industry. Stable Diffusion in 2022, with its powerful graphical capabilities and community strength, quickly caught up with Midjourney, a famous closed-source graphical model, and has already taken the lead in some aspects; the robust capabilities of open-source large language models, represented by Meta LLaMA 2, have made Google researchers reflect that "we don't have a moat, and neither does OpenAI"; and there are also emerging open-source leaders in various fields, such as Dolly, Falcon, etc. With its powerful community resources and cheaper cost of use, Open-source LLM quickly gained many business and individual users, acting as an indispensable force in the development of LLM.`,-1),T=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"100%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-4.png",alt:"image004"})])])])])],-1),A=e("br",null,null,-1),S=e("p",null,[e("strong",null,"Performance of open-source LLMs is rapidly catching up with closed-source")],-1),M=e("p",null,"Closed-source LLM represented by OpenAI ChatGPT4 started earlier, and the number of parameters and various performance metrics showed a tendency to outperform open-source models in the early stage. However, open-source models have a strong community and technical support, resulting in rapid performance growth. The most mature version of ChatGPT4 scored 1,181, while Llama 2, an open-source LLM launched less than four months ago, scored 1,051, with a difference of only 11%. It's worth noting that the rankings 4-9 are all open-source LLMs, indicating that the growth in open-source LLM performance is not an isolated case but an industry trend. Open-source LLMs are highly cost-effective due to their low usage costs and smaller performance gap compared to closed-source LLMs, which makes them attractive to increasing numbers of business and individual users. Please see the more detailed discussion of costs later.",-1),I=e("p",null,"Benefiting from the open nature of open-source models, users can easily fine-tune LLMs to fit different vertical application scenarios. Fine-tuned LLMs are more industry-specific than general-purpose LLMs, which is an advantage that closed-source models cannot provide.",-1),C=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-5.png",alt:"image005"})])])])])],-1),q=e("p",null,[t("Figure 2.5 "),e("a",{href:"https://en.wikipedia.org/wiki/Elo_rating_system",target:"_blank",rel:"noreferrer"},"ELO ratings"),t(" of LLMs based on user feedback")],-1),x=e("h4",{id:"_2-1-3-the-three-layers-of-the-llm",tabindex:"-1"},[t("2.1.3 The three layers of the LLM "),e("a",{class:"header-anchor",href:"#_2-1-3-the-three-layers-of-the-llm","aria-label":'Permalink to "2.1.3 The three layers of the LLM"'},"​")],-1),P=e("p",null,"The technical architecture of the LLM is divided into three main layers, as shown in the figure below. Open source has made significant contributions to the model layer, the developer tools layer, and the application layer. Each layer has its unique function and importance, and together, they form the complete architecture of the large-scale model technology. The subsequent sections (2.2, 2.3, 2.4) will discuss each layer in detail.",-1),z=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"80%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-6.png",alt:"image006"})])])])])],-1),O=a("",17),D=a("",7),F=a("",14),R=a("",19),G=e("br",null,null,-1),B=e("p",null,[t("Open-source language models (LLMs) are built with contributions from developers worldwide from different cultures, regions, and technical backgrounds. This is in contrast to closed-source models. The graph below shows that contributors from various countries, including China, India, Japan, Brazil, and others, have made significant contributions to the open-source community for generative AI and the United States. By including contributions from developers worldwide, the open-source LLM can be adapted to suit different regions' customs, languages, industries, and other usage habits. This will make the open-source LLM more versatile and appealing to a broader audience. "),e("br")],-1),E=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"80%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-11.png",alt:"image011"})])])])])],-1),j=a("",14),V=e("br",null,null,-1),H=e("p",null,[e("strong",null,"Provision of cloud hosting services")],-1),N=e("p",null,"Cloud growth has continued to exceed expectations since the development of cloud computing technology.The growing need for flexible and scalable infrastructure is driving IT organizations' cloud spending and increasing cloud penetration worldwide. Against this technological backdrop, there is a growing demand from users to reduce software O&M costs. Cloud hosting services are SaaS that enable customers to skip on-premise deployment and host software as a service directly on a cloud platform. By subscribing to SaaS services,clients can turn high upfront capital expenditures into small recurring expenditures, and relieve O&M pressure to a large extent. Some of the more successful open-source software companies include Databricks, HashiCorp, and others.",-1),W=e("p",null,"In the field of LLMs, Zhipu AI directly provides standard API products based on ChatGLM, so that customers can quickly build their own proprietary LLM applications, pricing according to the number of tokens of text actually processed by the model. The service is suitable for scenarios that require high level of knowledge, reasoning ability and creativity, such as advertisement copywriting, novel writing, knowledge-based writing, code generation, etc. The pricing is：0.005 yuan / thousand tokens.",-1),U=e("p",null,"At the same time, Zhipu AI also provides API interfaces for super-simulated LLMs (supporting character-based role-playing, extended multi-round memory, and individualized character dialogues) and vector LLMs (vectorizing the input text information so as to combine with vector databases, provide external knowledge bases for LLMs, and improve the accuracy of LLM inference).",-1),$=e("p",null,[t("Hugging Face also offers a cloud-hosted business model. The Hugging Face platform hosts a large number of open-source models and also offers a cloud-based solution, the Hugging Face Inference API, which allows users to easily deploy and run these models in the cloud via an API.This model combines the accessibility of an open-source model with the convenience of cloud hosting, allowing users to use it on demand without having to set up and manage a large infrastructure on their own. "),e("br")],-1),J=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-13.png",alt:"image013"})])])])])],-1),Z=e("br",null,null,-1),Q=e("p",null,[e("strong",null,"Development of commercial applications based on a foundation model")],-1),K=e("p",null,"Based on the base model to charge fees, refers to part of the open-source vendor's own base model is free open source, but the vendor based on the base model and developed a series of commercial applications, and for commercial applications to charge for the model, typical cases, such as Tongyi Qianwen.",-1),X=e("p",null,[t("AliCloud has developed eight applications based on its open-source base model Tongyi Qianqi：Tongyi Tingwu (speech recognition), Tongyi Xiaomei (to improve customer service efficiency), Tongyi Zhiwen (text comprehension), Tongyi Stardust (personalized roles), Tongyi Spirit Codes (to assist in programming), Tongyi Faerui (legal industry), Tongyi Renxin (pharmaceutical industry), and Tongyi Diaojin (financial industry).Each of these applications has a corresponding enterprise-level payment model. Also some of the apps include a individual-level payment model , such as Tongyi Tingwu. It mainly provides voice-to-text related services such as meeting minutes, and its charges are mainly calculated based on the length of the audio. "),e("br")],-1),Y=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-14.png",alt:"image014"})])])])])],-1),ee=e("br",null,null,-1),te=e("p",null,[e("strong",null,"Model-as-a-Service business model")],-1),oe=e("p",null,"The lowest level of Model as a Service (abbreviated to：MaaS) means to take the model as an important production element, design products and technologies around the model life cycle, and provide a wide variety of products and technologies starting from the development of the model, including data processing, feature engineering, training and tuning of the model, and services for the model.",-1),ne=e("p",null,[t('AliCloud initiated the "ModelScope Community" as the advocate of MaaS. In order to realize MaaS, AliCloud has made preparations in two aspects：One is to provide a model repository, which collects models, provides high-quality data, and can also be tuned for business scenarios. Model usage and computational need to be combined in order to provide a quick experience of the model so that a wide range of developers can quickly experience the effects of the model without having to coding. The second is to provide abstract interfaces or API interfaces so that developers can do secondary development for the model. In the face of specific application scenarios, providing fewer samples or zero samples, it is easy for developers to carry out secondary optimization of the model, which really allows the model to be applied to different scenarios. '),e("br")],-1),ie=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-15.png",alt:"image015"})])])])])],-1),ae=a("",11),se=e("br",null,null,-1),re=e("p",null,"To promote the development of AI applications, the developer tools layer plays an essential role in helping enterprises and individual developers to develop and deploy their final products. For enterprise developers, developer tools help to realize the deployment of LLMs in the industry, as well as the monitoring of the model to ensure the regular operation of the enterprise model. Other related functions include model evaluation, database inference, and supplementation of the model running process. For individual developers, developer tools help them simplify deployment steps and reduce development costs, inspiring the creation of more fine-tuned models for specific functions, such as Autotrain by Hugging Face, which allows developers to fine-tune open-source models based on private data with just a few mouse clicks. At the same time, the developer tools also help to establish the connection between the end-user and the LLM APP and even the deployment of the LLM on the end-user's device.",-1),le=e("p",null,[t("With the increasing maturity and advancement of development tools, more and more developers are venturing into development related to LLMs. These tools not only improve development efficiency but also lower the barrier to entry, enabling more innovative-thinking talent to participate in the field. From data processing and model training to performance optimization, these tools provide comprehensive support for developers. As a result, we have witnessed the birth of a diverse and active LLM development community with some cutting-edge projects and innovative applications. "),e("br")],-1),de=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-17.png",alt:"image017"})])])])])],-1),ce=e("br",null,null,-1),ue=e("p",null,[t("LLM development tools are blossoming, covering everything from data preparation and model construction to performance tuning, and they continue to push the frontiers of AI technology. Some tools focus on data annotation and cleaning so that developers can more easily obtain high-quality data; some tools are committed to improving the efficiency of fine-tuning so that the LLM is more in line with the customization needs; there are also tools responsible for the operation of the LLM monitoring, to provide timely feedback to the developers, users. These diverse tools promote technological innovation and provide developers with more choices, together building a vibrant and creative ecosystem for LLM development. There is no shortage of great open-source projects that greatly benefit both users and open-source companies. "),e("br")],-1),he=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-18.png",alt:"image018"})])])])])],-1),pe=e("br",null,null,-1),me=e("h4",{id:"_2-3-2-open-source-for-developer-tools-is-important",tabindex:"-1"},[t("2.3.2 Open source for developer tools is important "),e("a",{class:"header-anchor",href:"#_2-3-2-open-source-for-developer-tools-is-important","aria-label":'Permalink to "2.3.2 Open source for developer tools is important"'},"​")],-1),ge=e("p",null,[e("strong",null,"Supply-side benefits")],-1),fe=e("p",null,'Open-source developer tools are conducive to polishing and upgrading the product in different scenarios, which contributes to its rapid maturity. One of the main advantages of open-source developer tools is that they provide an extensive testing and application environment. Because open-source tools are freely available for use and modification by a variety of users and organizations, they are often applied and tested in diverse real-world scenarios and are thus "battle-tested. "This extensive use and feedback helps the product identify and fix potential defects more quickly while facilitating the development of new features and improvements to existing ones. Especially for startups，this is the fastest and most cost-effective way to get product feedback, promote product improvement, and help quickly bring more mature commercialized products to market.',-1),ye=e("p",null,[t("Open-source developer tools underlying products with high user stickiness are conducive to rapidly spreading the market. As mentioned earlier, developer tools contain many indispensable components of the LLM development process. Once developers become accustomed to specific tools, they tend to use them consistently because changing tools means relearning and adapting to the new tool's features and usage. Therefore, these products naturally have high user stickiness. "),e("br")],-1),be=e("p",null,[e("img",{src:"https://hackmd.io/_uploads/By-9g0d5T.jpg",alt:"FW-_aFHXEAMjI09"})],-1),ve=a("",13),we=e("br",null,null,-1),_e=e("p",null,[e("strong",null,"Establishing an ecology conducive to building open source industry standards")],-1),ke=e("p",null,[t("Developer tools, as the underlying tool layer, are decisive for the principle architecture of the upper model development. Collaboration with partners such as cloud vendors, open-source model vendors, and others helps to build consensus and establish industry standards, which is critical to ensure interoperability, compatibility, and consistency of user experience with development tools. Standardization reduces compatibility issues and enables easier integration and use of different products and services. For example, MongoDB leverages the community to form the industry standard for NoSQL RDMS. This active community not only brought high-quality, low-cost licenses to the early commercial versions of MongoDB but also served as the basis for the later Atlas (managed service). Based on the collaboration of the open-source community, Milvus launched Vector DB Bench (which can measure the performance of vector databases through the measurement of key metrics, allowing vector databases to maximize their potential), thus gradually establishing an industry standard for vector databases, and facilitating the selection of vector databases tailored to the needs of users. "),e("br")],-1),Le=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-21.png",alt:"image021"})])])])])],-1),Te=a("",11),Ae=a("",10),Se=e("br",null,null,-1),Me=e("p",null,[t("Zilliz's success represents a GPU-based giant data accelerator that provides an effective solution to organizations' growing data analytics needs. Zilliz's core project, the vector similarity search engine Milvus, is the world's first GPU-accelerated massive feature vector matching and retrieval engine. Relying on GPU acceleration, Milvus provides high-speed feature vector matching and multi-dimensional data joint query (joint query of features, labels, images, videos, text, and speech) and supports automatic database sharding and multi-replicas, which can interface with AI models such as TensorFlow, PyTorch, and MxNet, enabling second-level queries for billions of feature vectors. Milvus was open-sourced on GitHub in October 2019, and the number of Stars continues to grow at a high rate, reaching 25k+ in December 2023, with a developer community of over 200 contributors and 4000 + users. In the capital market, Zilliz received $43 million in Series B, the most significant single Series B financing for open-source infrastructure software worldwide. This indicates that investment institutions are optimistic about Zilliz's potential for future development. "),e("br")],-1),Ie=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-24.png",alt:"image024"})])])])])],-1),Ce=e("br",null,null,-1),qe=e("p",null,"Zilliz's main product is the Vector Database, a key piece of developer tools. It is a database system specialized in storing, indexing, and querying embedded vectors. This allows LLMs to store and read knowledge bases more efficiently and fine-tune models at a much lower cost. It will also play an important role in the evolution of AI-native applications.",-1),xe=e("p",null,[t("Zilliz is commercialized as Zilliz Cloud, with a monthly subscription business model. It is deployed in the form of SaaS, and determines the monthly subscription fee based on the number of vectors, vector dimensions, computational unit (CU) type, and average data length. Zilliz also offers a PaaS-based proprietary deployment service for scenarios with a high focus on data privacy and compliance, which is based on customized pricing."),e("br")],-1),Pe=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-25.png",alt:"image025"})])])])])],-1),ze=a("",5),Oe=e("br",null,null,-1),De=e("p",null,"A large number of open-source application layer products have also been born, which are mostly based on LLMs and fine-tuned with industry-specific datasets. Application layer tools customized for the industry offer better performance than the generic LLMs, and the open-source nature helps bueiness and consumer users using these applications to further customize their development to better fit the needs.",-1),Fe=e("p",null,[t("Open-source tools at the application layer facilitate integration across disciplines and industries. For example, industries such as medicine, finance, education, and retail are utilizing open-source AI tools to solve industry-specific problems, driving the adoption of the technology across all sectors. Open-source tools encourage experimentation and innovation due to low cost and low risk. Developers are free to experiment with new ideas and technologies, and this spirit of experimentation has greatly contributed to the application layer boom. "),e("br")],-1),Re=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_2/2-27.png",alt:"image027"})])])])])],-1),Ge=a("",15),Be=a("",36),Ee=a("",10),je=a("",7),Ve=e("br",null,null,-1),He=e("p",null,[t("Against the backdrop of generally low activity, there are also some open-source software that are overly active, again putting a lot of security O&M pressure on users. According to QAX, there will be 22,403 open-source projects with more than 100 versions in the mainstream open-source package ecosystem in 2022, compared to 19,265 and 13,411 in 2021 and 2020, respectively. "),e("br")],-1),Ne=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_3/3-4.png",alt:"image032"})])])])])],-1),We=e("br",null,null,-1),Ue=e("p",null,"Too little or too much activity poses a high security risk to users of the open-source ecosystem, and a balance is urgently needed to ensure the healthy and sustainable development of open-source software. A more scientific version management and release mechanism is needed to ensure that updates respond to security and functionality needs in a timely manner without disturbing users too frequently. For projects with insufficient activity, their activity can be enhanced by increasing community participation and providing incentives. For projects with frequent updates, more attention should be paid to communicating with users, providing clear update logs and support guidelines to help users better understand and adapt to these changes.",-1),$e=e("p",null,"At the same time, users should also be encouraged to actively participate in the feedback and contribution of the open-source project to form a positive interaction. Users' actual experience and feedback are important references for adjusting the update pace and optimizing software functions. By establishing a healthy user-developer interaction mechanism, we can effectively balance the activity and update frequency to ensure the safety and usability of the software.",-1),Je=e("p",null,[e("strong",null,"Some users are using software that is outdated or with version usage being disorganized")],-1),Ze=e("p",null,[t("According to QAX , many software projects use very outdated versions of open-source software, even versions released 30 years ago, with many vulnerabilities and very high risk exposure. One of the earliest software is IJG JPEG 6 released in 1995, which is still used by many projects. Older versions often come with older vulnerabilities, and there are still very old open-source vulnerabilities in some software projects. The oldest vulnerability is from 2002, 21 years ago, and is still used by 11 projects. "),e("br")],-1),Qe=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"90%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_3/3-5.png",alt:"image033"})])])])])],-1),Ke=a("",19),Xe=a("",6),Ye=a("",15),et=a("",52),tt=a("",17),ot=e("br",null,null,-1),nt=e("p",null,[t("Against the backdrop of a declining equity market, fund managers have generally reduced their allocations to private equity assets to maintain portfolio proportions; at the same time, due to the high volatility of venture capital and the uncertainty of the future global economic situation, the scale of venture capital fundraising in 2023 will drop significantly compared with that of previous years. Compared to an average of more than $250 billion annually over the past five years (2018-2022), venture capital commitments as of 2023Q3 amounted to just $116 billion (according to KPMG). Overlaying the trend of seven consecutive quarters of declining venture capital activity, fundraising will shrink significantly in 2023Q4 and for the full year. "),e("br")],-1),it=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"75%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-2.png",alt:"image039"})])])])])],-1),at=e("br",null,null,-1),st=e("p",null,[t("At the valuation level, investor caution is also growing. Compared to 2021 and 2022, the proportion of premium financing has decreased by about 10%, and the proportion of par and discount financing has risen by about 5%, which creates an obstacle to the exit of early-stage capital. "),e("br")],-1),rt=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"75%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-3.png",alt:"image040"})])])])])],-1),lt=a("",9),dt=e("br",null,null,-1),ct=e("p",null,[t("Analyzing from the perspective of financing scale of each round, the capital prefers medium-term financing such as B, C, D, and so on. This reflects the characteristics of commercial open-source companies：In the early stage, the technical details are still unclear, and the business model is not clear; however, when they gradually cross the start-up stage, commercial open-source companies will explode with stronger growth momentum, attracting more capital; in the later stage when the business model is gradually matured and the open-source product becomes well-known and generates stable cash flow, the need for financing will be reduced. "),e("br")],-1),ut=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"75%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-5.png",alt:"image042"})])])])])],-1),ht=e("br",null,null,-1),pt=e("p",null,[t("A total of 328 commercial open-source companies have received more than $10 million in funding over the past four years. Of these, the main concentration was in the US$10-50 million range, with a total of 210 rounds, or 64% of all rounds, in the US$10-20 million and US$20-50 million ranges. There were 49 rounds of $50-100 million and 46 rounds of $100-200 million, accounting for 29% of all rounds. A total of 23 companies received more than $200 million in funding, with two of them even receiving more than $500 million in a single round. "),e("br")],-1),mt=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"75%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-6.png",alt:"image043"})])])])])],-1),gt=a("",6),ft=e("br",null,null,-1),yt=e("p",null,[e("strong",null,"Increase in the size of RMB funds and a significant decrease in the size of foreign currency funds")],-1),bt=e("p",null,"In the first half of 2023, the number of new RMB funds launched was 3,840, a decrease of 13% compared to the same period last year. The total size of RMB funds reached US$339.5 billion, a 13% increase compared to the same period last year. The size of foreign currency funds was $24.7 billion, a significant decline of 67% from the previous year. Despite the increase in the number of foreign currency funds in 2023, their impact on the total size is small as most are small funds.",-1),vt=e("p",null,[t("This trend indicates that the domestic equity investment market prefers the more conservative investment style of RMB funds：and requires a higher degree of stability in the portfolio companies. For open-source business startups in China, simply following the market buzz is no longer enough to attract investment. Technological strength and long-term growth potential become key factors in assessing whether to make further investments. "),e("br")],-1),wt=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"85%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-8.png",alt:"image045"})])])])])],-1),_t=e("br",null,null,-1),kt=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"85%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-9.png",alt:"image046"})])])])])],-1),Lt=e("br",null,null,-1),Tt=e("p",null,[e("strong",null,"Economic recovery falls short of expectations and decline in overall investment volume and size")],-1),At=e("p",null,[t("Against the macro backdrop of unstable roots of economic recovery, slowdown in overall demand, and instability in external markets, the total number of investments in the H1 equity market in 2023 will be 3,750, a year-on-year decline of 31%; the total amount of investment supplied will be USD56.9 billion, a decline of 6% compared to the same period last year. Compared to the financing side where the size of newly established funds declined by 3%, a stronger contraction has been shown on the investment side, which further illustrates the cautious sentiment of investors, which is consistent with the trend shown by international markets. "),e("br")],-1),St=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"85%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-10.png",alt:"image047"})])])])])],-1),Mt=a("",9),It=e("br",null,null,-1),Ct=e("p",null,[e("strong",null,"ModelScope has become the first portal for domestic open source LLMs, marking the gradual growth of China's open-source AI community construction")],-1),qt=e("p",null,"ModelScope Community is an AI modeling community launched by Ali Dharma Institute in collaboration with the Open-source Development Committee of China Computer Federation (CCF), aiming to build a next-generation open-source model-as-a-service sharing platform, and strive to lower the threshold of AI applications. Since its launch, it has expanded rapidly：The community now has over 2,300 models, over 2.8 million developers, and over 100 million model downloads. Baichuan Intelligence, Wisdom Spectrum AI, Shanghai Artificial Intelligence Laboratory, IDEA Research Institute and other leading LLMing organizations use ModelScope as their open-source model debut platform.",-1),xt=e("p",null,[t('The ModelScope community upholds the concept of "Model as a Service" and treats AI models as an important element of production, providing services around the model lifecycle, from model pre-training to secondary tuning and finally to model deployment. Compared to the foreign community Hugging Face, ModelScope pays more attention to domestic needs, provides a large number of Chinese models, and promotes the application of relevant AI scenes in China. '),e("br")],-1),Pt=e("div",{style:{"margin-left":"auto","margin-right":"auto",width:"75%"}},[e("table",null,[e("thead",null,[e("tr",null,[e("th",null,[e("img",{src:"https://raw.githubusercontent.com//kaiyuanshe/2023-China-Open-Source-Report/main//public/image/commercialization/chapter_4/4-12.png",alt:"image049"})])])])])],-1),zt=e("br",null,null,-1),Ot=e("p",null,"The establishment and rapid development of the ModelScope community has set a benchmark for China's open-source community culture, which is conducive to further promoting the spread of open-source culture in China, attracting more creative, open-source spirit of technology creators, technology users to join, and promoting the further prosperity of China's open-source cause.",-1),Dt=e("h4",{id:"_4-2-3-domestic-open-source-company-financing-remains-hot",tabindex:"-1"},[t("4.2.3 Domestic Open Source Company Financing Remains Hot "),e("a",{class:"header-anchor",href:"#_4-2-3-domestic-open-source-company-financing-remains-hot","aria-label":'Permalink to "4.2.3 Domestic Open Source Company Financing Remains Hot"'},"​")],-1),Ft=e("p",null,"The market heat maintained in 2023, with several large investments taking place and some startups raising multiple rounds of funding in a year, reflecting the high level of investor interest. Open Source China is an open-source community platform company, including nearly 100,000 world-renowned open-source projects, under the banner of open-source community Landscape and Japan's old open-source community OSDN, and also owns the code hosting platform Gitee, which is the leading code hosting service platform in China, and has obtained a 775 million yuan of strategic financing in the B+ round; SelectDB develops and promotes open-source real-time data warehouse Apache Doris, and provides technical support and commercial services for Apache Doris users, and has obtained a new round of several hundred million yuan of financing so far. Flywheel Technology, which develops and promotes the open-source real-time data warehouse Apache Doris and provides technical support and commercial services for Apache Doris users, has obtained a new round of financing of hundreds of millions of yuan, and the total financing scale has reached nearly 1 billion yuan up to now; Lanboat Technology, which provides a new generation of cognitive intelligence platform based on NLP technology, has completed the investment of the Pre-A+ round, and the total financing scale has reached hundreds of millions of yuan in less than a year.",-1),Rt=e("p",null,"At present, the development of China's open-source ecosystem is still at an early stage, and the financing events in 2023 will mainly focus on round B and before, involving artificial intelligence, open-source communities, data warehouses and LLMing platforms, and other fields, with vast market opportunities.",-1),Gt=a("",2),Bt=a("",1);function Et(jt,Vt,Ht,Nt,Wt,Ut){const o=r("center");return d(),l("div",null,[u,n(o,null,{default:i(()=>[t(" Figure 2.1 Time to reach 100 million users for major apps (in months)")]),_:1}),h,p,m,n(o,null,{default:i(()=>[t(" Figure 2.2 Global AI Market Size (Trillions of Dollars)")]),_:1}),g,f,y,b,v,n(o,null,{default:i(()=>[t(" Figure 2.3 Cumulative number of AI / Machine Learning related papers published on Arxiv")]),_:1}),w,_,k,L,T,n(o,null,{default:i(()=>[t(" Figure 2.4 Emerging Open Source LLMs ")]),_:1}),A,S,M,I,C,n(o,null,{default:i(()=>[q]),_:1}),x,P,z,n(o,null,{default:i(()=>[t(" Figure 2.6 Technical Layers of the LLM ")]),_:1}),O,n(o,null,{default:i(()=>[t(" Figure 2.7 Increasing number of large model parameters ")]),_:1}),D,n(o,null,{default:i(()=>[t(" Figure 2.8 Cost Comparison of Calling OpenAI APIs and Deploying Open Source Models on the AWS Cloud ")]),_:1}),F,n(o,null,{default:i(()=>[t(" Figure 2.9 Performance Ranking of WizardMath ")]),_:1}),R,n(o,null,{default:i(()=>[t(" Figure 2.10 Changes in the number of generative AI-related projects open-sourced on GitHub (Source: GitHub)")]),_:1}),G,B,E,n(o,null,{default:i(()=>[t(" Figure 2.11 Top 10 global communities creating the most generative AI projects on GitHub (Source：Github)")]),_:1}),j,n(o,null,{default:i(()=>[t(" Figure 2.12 Zhipu AI's Pricing Model for Private Deployment ")]),_:1}),V,H,N,W,U,$,J,n(o,null,{default:i(()=>[t(" Figure 2.13 Hugging Face Cloud Platform Charges ")]),_:1}),Z,Q,K,X,Y,n(o,null,{default:i(()=>[t(" Figure 2.14 Tongyi Tingwu Pricing Model ")]),_:1}),ee,te,oe,ne,ie,n(o,null,{default:i(()=>[t(" Figure 2.15 AliCloud：Model-as-a-Service ")]),_:1}),ae,n(o,null,{default:i(()=>[t(" Figure 2.16 Location of Developer Tools in the AI LLM Chain ")]),_:1}),se,re,le,de,n(o,null,{default:i(()=>[t(" Figure 2.17 Growing Number of AI LLM Developers ")]),_:1}),ce,ue,he,n(o,null,{default:i(()=>[t(" Figure 2.18 Large number of development tools covering different levels of LLM development ")]),_:1}),pe,me,ge,fe,ye,be,n(o,null,{default:i(()=>[t(" Figure 2.19 High user stickiness of open source development tools ")]),_:1}),ve,n(o,null,{default:i(()=>[t(" Figure 2.20 MongoDB Sales Revenue by Product ")]),_:1}),we,_e,ke,Le,n(o,null,{default:i(()=>[t(" Figure 2.21 Vector database evaluation results ")]),_:1}),Te,n(o,null,{default:i(()=>[t(" Figure 2.22 Dify.AI subscription pricing ")]),_:1}),Ae,n(o,null,{default:i(()=>[t(" Figure 2.23 Zilliz Global Users (from company website)")]),_:1}),Se,Me,Ie,n(o,null,{default:i(()=>[t(" Figure 2.24 Zilliz Github Community Operations ")]),_:1}),Ce,qe,xe,Pe,n(o,null,{default:i(()=>[t(" Figure 2.25 Example of Zilliz Price Calculator ")]),_:1}),ze,n(o,null,{default:i(()=>[t(" Figure 2.26 A wildly diverse array of AI application layer products (source：Sequoia)")]),_:1}),Oe,De,Fe,Re,n(o,null,{default:i(()=>[t(" Figure 2.27 Mapping of open-source tools for application testing (with examples of selected products in each domain)")]),_:1}),Ge,n(o,null,{default:i(()=>[t(" Figure 2.28 Application Layer Open-source Growth Flywheel ")]),_:1}),Be,n(o,null,{default:i(()=>[t(" Figure 3.1 Open Source Codebase Vulnerabilities (Data Source：Synopsys)")]),_:1}),Ee,n(o,null,{default:i(()=>[t(" Figure 3.2 Three-Year Comparison of Average Defect Density of Open Source Software ")]),_:1}),n(o,null,{default:i(()=>[t("(Source：2023 China Software Supply Chain Security Analysis Report)")]),_:1}),je,n(o,null,{default:i(()=>[t(" Figure 3.3 Statistics of Inactive Open Source Projects ")]),_:1}),Ve,He,Ne,n(o,null,{default:i(()=>[t(" Figure 3.4 Extremely Active Program Statistics ")]),_:1}),We,Ue,$e,Je,Ze,Qe,n(o,null,{default:i(()=>[t(" Figure 3.5 Aged Open Source Vulnerabilities and Their Usage ")]),_:1}),Ke,n(o,null,{default:i(()=>[t(" Figure 3.6 Open Source License Classification ")]),_:1}),Xe,n(o,null,{default:i(()=>[t(" Figure 3.7 License Logic Relationships ")]),_:1}),Ye,n(o,null,{default:i(()=>[t(" Figure 3.8 GPL License Related Litigation ")]),_:1}),et,n(o,null,{default:i(()=>[t(" Figure 3.9 Classification of hallucinations by Harbin Institute of Technology ")]),_:1}),tt,n(o,null,{default:i(()=>[t(" Figure 4.1 Global Venture Capital Activity (Source：KPMG)")]),_:1}),ot,nt,it,n(o,null,{default:i(()=>[t(" Figure 4.2 Global Venture Capital Fundraising Scale (Source：KPMG)")]),_:1}),at,st,rt,n(o,null,{default:i(()=>[t(" Figure 4.3 Global VC Premium, Parity, and Decline Investment Ratios (Source：KPMG)")]),_:1}),lt,n(o,null,{default:i(()=>[t(" Figure 4.4 Amount of Global VC Funds Invested in Commercialized Open-source Software Companies (Source：OSS Capital)")]),_:1}),dt,ct,ut,n(o,null,{default:i(()=>[t(" Figure 4.5 Distribution of Financing Rounds for Commercialized Open Source Software Companies ($M) (Source：OSS Capital)")]),_:1}),ht,pt,mt,n(o,null,{default:i(()=>[t(" Figure 4.6 Distribution of Financing Rounds for Commercialized Open-source Software Companies ($M) (Source：OSS Capital)")]),_:1}),gt,n(o,null,{default:i(()=>[t(" Figure 4.7 Domestic Private Equity Fund Contributions and Volume (Source：investment.com, KPMG)")]),_:1}),ft,yt,bt,vt,wt,n(o,null,{default:i(()=>[t(" Figure 4.8 Size and number of domestic private equity RMB funds (Source：KPMG)")]),_:1}),_t,kt,n(o,null,{default:i(()=>[t(" Figure 4.9 Domestic Private Equity Foreign Currency Fund Size and Volume (Source：KPMG)")]),_:1}),Lt,Tt,At,St,n(o,null,{default:i(()=>[t(" Figure 4.10 Amount and number of investments in the domestic equity market (Source：KPMG)")]),_:1}),Mt,n(o,null,{default:i(()=>[t(" Figure 4.11 Map of domestic AI-related tech companies' open source projects and open source companies (partial)")]),_:1}),It,Ct,qt,xt,Pt,n(o,null,{default:i(()=>[t(" Figure 4.12 So far, ModelScope community has 11 model classes including LLM, zero-sample learning, etc. ")]),_:1}),zt,Ot,Dt,Ft,Rt,n(o,null,{default:i(()=>[t(" Table 4.1 Investment and Financing of Domestic Open Source Software Startups (slide to right to view full content) ")]),_:1}),n(o,null,{default:i(()=>[t(" (Github statistics as of December 7, 2023) ")]),_:1}),Gt,n(o,null,{default:i(()=>[t(" Table 4.2 Investment and Financing of Domestic Open-source LLMing Startups (slide to right to view full content) ")]),_:1}),n(o,null,{default:i(()=>[t(" (Hugging Face statistics as of December 7, 2023) ")]),_:1}),Bt])}const Zt=s(c,[["render",Et]]);export{Jt as __pageData,Zt as default};
